import csv
import io
import re
from typing import List
import pandas as pd
from json_repair import repair_json
from mongodb.actions.response_crud import upsert_response


def parse_psv_to_array(psv_string: str) -> List[dict]:
    """Parse Pipe-Separated Values"""
    if not psv_string or not isinstance(psv_string, str):
        return []
    
    try:
        psv_string = psv_string.lstrip('\ufeff').strip()
        csv_file = io.StringIO(psv_string)
        reader = csv.DictReader(csv_file, delimiter='|')
        
        result = []
        for row in reader:
            cleaned_row = {
                k.strip(): v.strip() if v else ""
                for k, v in row.items()
                if k and k.strip()
            }
            if cleaned_row:
                result.append(cleaned_row)
        
        print(f"‚úÖ ƒê√£ parse PSV th√†nh c√¥ng: {len(result)} rows")
        return result
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi parse PSV: {e}")
        return []


def preprocess_csv_data(csv_string: str) -> str:
    """
    Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu CSV s·ª≠ d·ª•ng pandas ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c.
    
    Args:
        csv_string: Chu·ªói CSV g·ªëc t·ª´ AI response
        
    Returns:
        Chu·ªói CSV ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch
    """
    if not csv_string or not isinstance(csv_string, str):
        return ""
    
    try:
        # Lo·∫°i b·ªè BOM v√† chu·∫©n h√≥a line endings
        cleaned = csv_string.lstrip('\ufeff')
        cleaned = cleaned.replace('\r\n', '\n').replace('\r', '\n')
        
        # FIX 1: X·ª≠ l√Ω escaped quotes \" th√†nh ""
        # CSV standard s·ª≠ d·ª•ng "" ƒë·ªÉ escape quote trong quoted field
        cleaned = cleaned.replace('\\"', '""')
        
        # FIX 2: X·ª≠ l√Ω literal \n trong quoted fields
        # S·ª≠ d·ª•ng regex ƒë·ªÉ t√¨m v√† replace \n trong quoted fields
        def replace_literal_newlines_in_quotes(text):
            """
            Replace literal \\n with space inside quoted CSV fields
            X·ª≠ l√Ω c·∫£ tr∆∞·ªùng h·ª£p c√≥ escaped quotes
            """
            result = []
            in_quotes = False
            i = 0
            
            while i < len(text):
                char = text[i]
                
                # Toggle quote state
                if char == '"':
                    # Check if it's escaped quote ""
                    if i + 1 < len(text) and text[i + 1] == '"':
                        result.append('""')
                        i += 2
                        continue
                    else:
                        in_quotes = not in_quotes
                        result.append(char)
                        i += 1
                        continue
                
                # Replace \n with space when inside quotes
                if in_quotes and char == '\\' and i + 1 < len(text) and text[i + 1] == 'n':
                    result.append(' ')  # Replace \n with space
                    i += 2
                    continue
                
                result.append(char)
                i += 1
            
            return ''.join(result)
        
        cleaned = replace_literal_newlines_in_quotes(cleaned)
        
        # ƒê·ªçc CSV b·∫±ng pandas v·ªõi c√°c t√πy ch·ªçn x·ª≠ l√Ω l·ªói
        df = pd.read_csv(
            io.StringIO(cleaned),
            skipinitialspace=True,  # B·ªè kho·∫£ng tr·∫Øng ƒë·∫ßu field
            skip_blank_lines=True,   # B·ªè d√≤ng tr·ªëng
            on_bad_lines='skip',     # B·ªè qua d√≤ng l·ªói
            encoding='utf-8',
            quotechar='"',
            doublequote=True,  # X·ª≠ l√Ω "" nh∆∞ escaped quote
            escapechar=None    # Kh√¥ng d√πng escape char
        )
        
        # Lo·∫°i b·ªè c√°c d√≤ng tr√πng l·∫∑p
        df = df.drop_duplicates()
        
        # Lo·∫°i b·ªè c√°c d√≤ng c√≥ t·∫•t c·∫£ gi√° tr·ªã l√† NaN
        df = df.dropna(how='all')
        
        # Trim kho·∫£ng tr·∫Øng cho t·∫•t c·∫£ c√°c c·ªôt string
        for col in df.columns:
            if df[col].dtype == 'object':
                df[col] = df[col].str.strip()
        
        # Chuy·ªÉn ƒë·ªïi l·∫°i th√†nh CSV string
        cleaned_csv = df.to_csv(index=False, lineterminator='\n', quoting=csv.QUOTE_MINIMAL)
        
        print(f"üßπ ƒê√£ ti·ªÅn x·ª≠ l√Ω CSV b·∫±ng pandas: {len(csv_string)} -> {len(cleaned_csv)} k√Ω t·ª±, {len(df)} rows")
        
        return cleaned_csv
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω CSV b·∫±ng pandas: {e}")
        print(f"‚ö†Ô∏è CSV g√¢y l·ªói (100 k√Ω t·ª± ƒë·∫ßu): {csv_string[:100]}")
        print("üîÑ Fallback sang x·ª≠ l√Ω th·ªß c√¥ng...")
        
        # Fallback: x·ª≠ l√Ω c∆° b·∫£n n·∫øu pandas th·∫•t b·∫°i
        cleaned = csv_string.lstrip('\ufeff')
        cleaned = cleaned.replace('\r\n', '\n').replace('\r', '\n')
        cleaned = cleaned.replace('\\"', '""')
        
        # Replace literal \n in quoted fields (simple version)
        def replace_literal_newlines_in_quotes(text):
            result = []
            in_quotes = False
            i = 0
            
            while i < len(text):
                char = text[i]
                
                if char == '"':
                    if i + 1 < len(text) and text[i + 1] == '"':
                        result.append('""')
                        i += 2
                        continue
                    else:
                        in_quotes = not in_quotes
                        result.append(char)
                        i += 1
                        continue
                
                if in_quotes and char == '\\' and i + 1 < len(text) and text[i + 1] == 'n':
                    result.append(' ')
                    i += 2
                    continue
                
                result.append(char)
                i += 1
            
            return ''.join(result)
        
        cleaned = replace_literal_newlines_in_quotes(cleaned)
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
        
        return cleaned


def parse_csv_to_array(csv_string: str) -> List[dict]:
    """
    Parse chu·ªói CSV th√†nh danh s√°ch c√°c dictionary.
    
    Args:
        csv_string: Chu·ªói CSV v·ªõi header ·ªü d√≤ng ƒë·∫ßu ti√™n
        
    Returns:
        List c√°c dictionary, m·ªói dictionary l√† m·ªôt row c·ªßa CSV
    """
    if not csv_string or not isinstance(csv_string, str):
        return []
    
    try:
        # Ti·ªÅn x·ª≠ l√Ω CSV tr∆∞·ªõc khi parse
        cleaned_csv = preprocess_csv_data(csv_string)
        
        if not cleaned_csv:
            return []
        
        # S·ª≠ d·ª•ng StringIO ƒë·ªÉ ƒë·ªçc CSV t·ª´ string
        csv_file = io.StringIO(cleaned_csv)
        reader = csv.DictReader(csv_file)
        
        # Chuy·ªÉn ƒë·ªïi th√†nh list of dictionaries v√† l√†m s·∫°ch values
        result = []
        for row in reader:
            # L√†m s·∫°ch gi√° tr·ªã c·ªßa m·ªói field
            cleaned_row = {
                key: value.strip() if isinstance(value, str) else value
                for key, value in row.items()
                if key is not None  # B·ªè qua c√°c c·ªôt kh√¥ng c√≥ header
            }
            result.append(cleaned_row)
        
        print(f"‚úÖ ƒê√£ parse CSV th√†nh c√¥ng: {len(result)} rows")
        return result
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi parse CSV: {e}")
        return []


def parse_and_save_ai_responses(raw_responses: List[str], phase_id: str) -> List[dict]:
    """
    Parse danh s√°ch JSON responses t·ª´ AI, lo·∫°i b·ªè duplicates theo agent_source,
    chuy·ªÉn ƒë·ªïi data t·ª´ CSV sang array, th√™m phaseId v√† l∆∞u v√†o MongoDB.
    
    Args:
        raw_responses: Danh s√°ch c√°c chu·ªói JSON t·ª´ AI response
        phase_id: ID c·ªßa phase ƒë·ªÉ g·∫Øn v√†o m·ªói response
        
    Returns:
        List c√°c response ƒë√£ ƒë∆∞·ª£c parse v√† l∆∞u th√†nh c√¥ng
    """
    list_result = []
    
    # Parse JSON v√† lo·∫°i b·ªè duplicates theo agent_source
    for jsondata in raw_responses:
        try:
            final_data = repair_json(jsondata, return_objects=True)
            
            # Ki·ªÉm tra final_data c√≥ ph·∫£i dict kh√¥ng
            if not isinstance(final_data, dict):
                print(f"‚ö†Ô∏è repair_json tr·∫£ v·ªÅ kh√¥ng ph·∫£i dict: {type(final_data)}")
                # N·∫øu l√† list, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
                if isinstance(final_data, list) and len(final_data) > 0:
                    final_data = final_data[0]
                    print(f"‚úÖ ƒê√£ l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n t·ª´ list")
                else:
                    print(f"‚ö†Ô∏è B·ªè qua response kh√¥ng h·ª£p l·ªá")
                    continue
            
            # Ki·ªÉm tra xem agent_source ƒë√£ t·ªìn t·∫°i ch∆∞a
            existing_item = next(
                (item for item in list_result if item.get('agent_source') == final_data.get('agent_source')), 
                None
            )
            
            if existing_item:
                # C·∫≠p nh·∫≠t item c≈© v·ªõi data m·ªõi
                idx = list_result.index(existing_item)
                list_result[idx] = final_data
            else:
                list_result.append(final_data)
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi parse JSON: {e}")
            continue
    
    # Th√™m phaseId v√† l∆∞u v√†o MongoDB
    saved_results = []
    for item in list_result:
        # Ki·ªÉm tra item c√≥ ph·∫£i dict kh√¥ng
        if not isinstance(item, dict):
            print(f"‚ö†Ô∏è Item kh√¥ng ph·∫£i dict, b·ªè qua: {type(item)} - {item}")
            continue
        
        # Th√™m phaseId v√†o item
        item["phaseId"] = phase_id
        
        # Parse data t·ª´ CSV sang array n·∫øu data_format l√† "csv"
        data_format = item.get("data_format", "").lower()
        if data_format == "csv" and item.get("data"):
            csv_data = item.get("data", "")
            #parsed_data = parse_csv_to_array(csv_data)
            parsed_data = parse_psv_to_array(csv_data)
            print(f"Parsed CSV: {parsed_data}")
            item["data"] = parsed_data
            print(f"üìä ƒê√£ chuy·ªÉn ƒë·ªïi CSV sang array cho agent: {item.get('agent_source')}")
        
        # L·∫•y agent_source ƒë·ªÉ l√†m key cho upsert
        agent_source = item.get("agent_source", "")
        
        # Ch·ªâ l∆∞u n·∫øu c√≥ agent_source (b·ªè qua c√°c response kh√¥ng h·ª£p l·ªá)
        if agent_source:
            try:
                upsert_response(phase_id, agent_source, item)
                print(f"‚úÖ ƒê√£ l∆∞u response t·ª´ agent: {agent_source}")
                saved_results.append(item)
            except Exception as e:
                print(f"‚ùå Item b·ªã l·ªói: {item}")
                print(f"‚ùå L·ªói khi l∆∞u response t·ª´ agent {agent_source}: {e}")
        else:
            # V·∫´n th√™m v√†o k·∫øt qu·∫£ tr·∫£ v·ªÅ d√π kh√¥ng l∆∞u ƒë∆∞·ª£c
            saved_results.append(item)
    
    return saved_results


def parse_ai_responses(raw_responses: List[str]) -> List[dict]:
    """
    Parse danh s√°ch JSON responses t·ª´ AI, lo·∫°i b·ªè duplicates theo agent_source.
    Kh√¥ng l∆∞u v√†o MongoDB.
    
    Args:
        raw_responses: Danh s√°ch c√°c chu·ªói JSON t·ª´ AI response
        
    Returns:
        List c√°c response ƒë√£ ƒë∆∞·ª£c parse
    """
    list_result = []
    
    for jsondata in raw_responses:
        try:
            final_data = repair_json(jsondata, return_objects=True)
            
            # Ki·ªÉm tra xem agent_source ƒë√£ t·ªìn t·∫°i ch∆∞a
            existing_item = next(
                (item for item in list_result if item.get('agent_source') == final_data.get('agent_source')), 
                None
            )
            
            if existing_item:
                idx = list_result.index(existing_item)
                list_result[idx] = final_data
            else:
                list_result.append(final_data)
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi parse JSON: {e}")
            continue
    
    return list_result
